{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "- https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Neuron/index.html\n",
    "- https://github.com/julienr/ipynb_playground\n",
    "- http://ataspinar.com/2016/12/22/the-perceptron/\n",
    "- https://www.quora.com/Why-do-we-use-the-derivatives-of-activation-functions-in-a-neural-network\n",
    "- https://www.youtube.com/watch?v=OVHc-7GYRo4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "*Perceptron* is a mathematical model of a biological neuron.\n",
    "<img src=\"https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Neuron/images/bioneuron.jpg\"/>\n",
    "\n",
    "Each signal represented as numerical values.  \n",
    "Each input value is multimpled by a value called **weight**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparition to a real biological neuron\n",
    "\n",
    "#### Biological model\n",
    "\n",
    "- Electrical signals are modulated in various amounts at the synapses\n",
    "between the dendrite and axons.\n",
    "- Neuron fires an output signal only when the total strength of the input signals exceed a certain threshold.\n",
    "\n",
    "<img src=\"https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Neuron/images/bioneuron.jpg\" height=30%/>\n",
    "\n",
    "#### Mathematical model\n",
    "- Each input is multiplied by a value called the weight.\n",
    "- An output is calculed by wighted sum of the inputs to represent the total strength of the input signals, and applying a step function of the sum to determine its output.\n",
    "\n",
    "<img src=\"https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/Neuron/images/artificial.jpg\" height=30%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main components\n",
    "- Training inputs set - a list of input data which was supplied by trainer for perceptron. It must be accompained with appropraite training result set.\n",
    "- Training result set - a list of result for each entity for training inputs set. That is prepared by a trainer, and ANN look at it to check how close to the right value it is.\n",
    "- Weights - Values describing  relationships between inputs\n",
    "- Activation function.\n",
    "- Derivative function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron implementation\n",
    "\n",
    "First we need to assume our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://ataspinar.com/wp-content/uploads/2016/11/perceptron_schematic_overview.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see a simple perceptron neural network. Its basic elements are:  \n",
    "1. $X$ is a list of values for  *N*-th case.  \n",
    "2. $R$ is a list of right values for  *N*-th case. That means for *n*-case a neural network should produce $r _n$.\n",
    "3. $W$ is a matrix with a synaptic neuron weights.  \n",
    "4. A unit step function (also called as activation function) is named $ \\theta (z)$. For $ \\theta (z)$ we will use sigmoid function (But you may choose any you want).\n",
    "\n",
    "$$  \\theta (z) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^-z }  $$ \n",
    "\n",
    "<img src=\"https://qph.fs.quoracdn.net/main-qimg-07066668c05a556f1ff25040414a32b7\" />\n",
    "4. A derivative function $S(x)$ - is a derivative function of $ \\theta (z) $. It help us to measure the steepness of the graph of a function at some particular point on the graph. When we get the activation output value, i.e. the input values have went throught a neural network, we check how much the output is derivative from training set result. For that we simple calculate derivativence between the right output *R* and a output *L* from the neural network:\n",
    "\n",
    "  $$ \\mathbf{error} = \\mathbf{L} - \\mathbf{R} $$\n",
    "  \n",
    "  Then we want to calculate how we need to change our weights to make an output of the neural network become closer to the right output for given training set.   \n",
    "  That's where a derivation comes in! It shows whether we need to move to - /+ destination (due to derivative nature) and how much.\n",
    "\n",
    "$$ \\frac{d}{dz}\\theta(z) = \\theta(z)(1 - \\theta(z)) $$\n",
    "  \n",
    "  The diffirential of Sigmoid function is:\n",
    "  \n",
    "$$ \\frac{d}{dx}S(x) = S(x)(1 - S(x)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron step by step\n",
    "Mathematically,  a perceptron works the following way:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Training sets $X$ (shape 3x3):\n",
    "\\begin{equation*}\n",
    "\\mathbf{X}  =  \n",
    "\\begin{vmatrix}\n",
    "\\mathbf{x _\\mathbf{11}} & \\mathbf{x _\\mathbf{12}} & \\mathbf{x _\\mathbf{13}} \\\\\n",
    "\\mathbf{x _\\mathbf{21}} & \\mathbf{x _\\mathbf{22}} & \\mathbf{x _\\mathbf{33}} \\\\\n",
    "\\mathbf{x _\\mathbf{31}} & \\mathbf{x _\\mathbf{32}} & \\mathbf{x _\\mathbf{33}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Training sets result $R$ (shape 3X1):\n",
    "\\begin{equation*}\n",
    "\\mathbf{R} =  \n",
    "\\begin{vmatrix}\n",
    "\\mathbf{r_\\mathbf{1}} \\\\\n",
    "\\mathbf{r_\\mathbf{2}} \\\\\n",
    "\\mathbf{r_\\mathbf{3}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Synaptic weights $W$ (shape 3x1):\n",
    "\\begin{equation*}\n",
    "\\mathbf{W} =  \\begin{vmatrix}\n",
    "\\mathbf{w_\\mathbf{1}} \\\\\n",
    "\\mathbf{w_\\mathbf{2}} \\\\\n",
    "\\mathbf{w_\\mathbf{3}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Sum of weights *O*:\n",
    "    \n",
    "\\begin{equation*}\n",
    "\\mathbf{X} * \\mathbf{W} =  \\begin{vmatrix}\n",
    "\\mathbf{x _\\mathbf{11}} & \\mathbf{x _\\mathbf{12}} & \\mathbf{x _\\mathbf{13}} \\\\\n",
    "\\mathbf{x _\\mathbf{21}} & \\mathbf{x _\\mathbf{22}} & \\mathbf{x _\\mathbf{33}} \\\\\n",
    "\\mathbf{x _\\mathbf{31}} & \\mathbf{x _\\mathbf{32}} & \\mathbf{x _\\mathbf{33}} \\\\\n",
    "\\end{vmatrix} * \n",
    "\\begin{vmatrix}\n",
    "\\mathbf{w_\\mathbf{1}} \\\\\n",
    "\\mathbf{w_\\mathbf{2}} \\\\\n",
    "\\mathbf{w_\\mathbf{3}} \\\\\n",
    "\\end{vmatrix} = \n",
    "\\begin{vmatrix}\n",
    "\\mathbf{x _\\mathbf{11}} * \\mathbf{w_\\mathbf{1}} + \\mathbf{x _\\mathbf{12}} * \\mathbf{w_\\mathbf{2}} + \\mathbf{x _\\mathbf{13}} * \\mathbf{w_\\mathbf{3}} \\\\\n",
    "\\mathbf{x _\\mathbf{21}} * \\mathbf{w_\\mathbf{1}} + \\mathbf{x _\\mathbf{22}} * \\mathbf{w_\\mathbf{2}} + \\mathbf{x _\\mathbf{23}} * \\mathbf{w_\\mathbf{3}}\\\\\n",
    "\\mathbf{x _\\mathbf{31}} * \\mathbf{w_\\mathbf{1}} + \\mathbf{x _\\mathbf{32}} * \\mathbf{w_\\mathbf{2}} + \\mathbf{x _\\mathbf{33}} * \\mathbf{w_\\mathbf{3}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate the activation function result. This is actual result of a neural network's work.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{O} = \\mathbf{sigmoid(X*W)} = \n",
    "\\mathbf{sygmoid(\n",
    "\\begin{vmatrix}\n",
    "\\mathbf{x _\\mathbf{11}} * \\mathbf{w_\\mathbf{11}} + \\mathbf{x _\\mathbf{12}} * \\mathbf{w_\\mathbf{21}} + \\mathbf{x _\\mathbf{13}} * \\mathbf{w_\\mathbf{31}} \\\\\n",
    "\\mathbf{x _\\mathbf{21}} * \\mathbf{w_\\mathbf{11}} + \\mathbf{x _\\mathbf{22}} * \\mathbf{w_\\mathbf{21}} + \\mathbf{x _\\mathbf{23}} * \\mathbf{w_\\mathbf{31}}\\\\\n",
    "\\mathbf{x _\\mathbf{31}} * \\mathbf{w_\\mathbf{11}} + \\mathbf{x _\\mathbf{32}} * \\mathbf{w_\\mathbf{21}} + \\mathbf{x _\\mathbf{33}} * \\mathbf{w_\\mathbf{31}} \\\\\n",
    "\\end{vmatrix})}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{O}= \n",
    "\\begin{vmatrix}\n",
    "\\mathbf{sigmoid}(\\mathbf{x _\\mathbf{11}} * \\mathbf{w_\\mathbf{1}} + \\mathbf{x _\\mathbf{12}} * \\mathbf{w_\\mathbf{2}} + \\mathbf{x _\\mathbf{13}} * \\mathbf{w_\\mathbf{3}}) \\\\\n",
    "\\mathbf{sigmoid}(\\mathbf{x _\\mathbf{21}} * \\mathbf{w_\\mathbf{1}} + \\mathbf{x _\\mathbf{22}} * \\mathbf{w_\\mathbf{2}} + \\mathbf{x _\\mathbf{23}} * \\mathbf{w_\\mathbf{3}})\\\\\n",
    "\\mathbf{sigmoid}(\\mathbf{x _\\mathbf{31}} * \\mathbf{w_\\mathbf{1}} + \\mathbf{x _\\mathbf{32}} * \\mathbf{w_\\mathbf{2}} + \\mathbf{x _\\mathbf{33}} * \\mathbf{w_\\mathbf{3}}) \\\\\n",
    "\\end{vmatrix}=\n",
    "\\begin{vmatrix}\n",
    "\\mathbf{o _\\mathbf{1}} \\\\\n",
    "\\mathbf{o _\\mathbf{2}} \\\\\n",
    "\\mathbf{o _\\mathbf{3}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Calculare the error.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{error} = \\mathbf{R} - \\mathbf{O} = \n",
    "\\begin{vmatrix}\n",
    "\\mathbf{r_\\mathbf{1}} \\\\\n",
    "\\mathbf{r_\\mathbf{2}} \\\\\n",
    "\\mathbf{r_\\mathbf{3}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\mathbf{-}\n",
    "\\begin{vmatrix}\n",
    "\\mathbf{o _\\mathbf{11}} \\\\\n",
    "\\mathbf{o _\\mathbf{11}} \\\\\n",
    "\\mathbf{o _\\mathbf{11}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\mathbf{=}\n",
    "\\begin{vmatrix}\n",
    "\\mathbf{r_\\mathbf{1}} - \\mathbf{o _\\mathbf{1}} \\\\\n",
    "\\mathbf{r_\\mathbf{1}} - \\mathbf{o _\\mathbf{1}} \\\\\n",
    "\\mathbf{r_\\mathbf{1}} - \\mathbf{o _\\mathbf{1}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\mathbf{=}\n",
    "\\begin{vmatrix}\n",
    "\\mathbf{e_\\mathbf{1}} \\\\\n",
    "\\mathbf{e_\\mathbf{1}} \\\\\n",
    "\\mathbf{e_\\mathbf{1}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Make an adjustment of synaptric weights\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{W}^{'}\n",
    "\\mathbf{=}\n",
    "\\mathbf{W} + \\mathbf{X}^{T}*\\mathbf{error}*\\mathbf{S(O)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{W}^{'}\n",
    "\\mathbf{=}\n",
    "\\mathbf{W} =  \n",
    "\\begin{vmatrix}\n",
    "\\mathbf{w_\\mathbf{1}} \\\\\n",
    "\\mathbf{w_\\mathbf{2}} \\\\\n",
    "\\mathbf{w_\\mathbf{3}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\mathbf{+}\n",
    "\\begin{vmatrix}\n",
    "\\mathbf{x _\\mathbf{11}} & \\mathbf{x _\\mathbf{21}} & \\mathbf{x _\\mathbf{31}} \\\\\n",
    "\\mathbf{x _\\mathbf{12}} & \\mathbf{x _\\mathbf{22}} & \\mathbf{x _\\mathbf{23}} \\\\\n",
    "\\mathbf{x _\\mathbf{13}} & \\mathbf{x _\\mathbf{21}} & \\mathbf{x _\\mathbf{33}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\mathbf{*}\n",
    "\\begin{vmatrix}\n",
    "\\mathbf{e_\\mathbf{1}} \\\\\n",
    "\\mathbf{e_\\mathbf{1}} \\\\\n",
    "\\mathbf{e_\\mathbf{1}} \\\\\n",
    "\\end{vmatrix}\n",
    "\\mathbf{*}\n",
    "\\begin{vmatrix}\n",
    "\\mathbf{S(\\mathbf{o _\\mathbf{1}})} \\\\\n",
    "\\mathbf{S(\\mathbf{o _\\mathbf{2}})} \\\\\n",
    "\\mathbf{S(\\mathbf{o _\\mathbf{3}})} \\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Go to step 4 and repeat until we exceed all iterations. That is what is called \"training\" - we try to calculate the output of a neural network so that the output as near to the right training set output (as it should be) as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, if you need only to ask a neural network what it thinks to be if you supply to it inputs $X(x_1,x_2,..x_n)$, you just stop after 5 step - that you get the output of activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then to use and when not to use\n",
    "- https://www.coursera.org/lecture/neural-networks/what-perceptrons-can-t-do-15-min-SUTuA  \n",
    "Perceptron is good as a binary threshold.Perceptron is usually used to classify the data into two parts. Therefore, it is also known as a Linear Binary Classifier.  \n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*xsR57_PO8U7PB_ItLslLmA.png\"/>\n",
    "To reach better result, you should supply more features to perceptron as inputs(features are something, which help determine one thing from another, i.e. cats have long vibrix (усы), but dogs haven't, also dogs can be really huge, cats usually not).\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Perceptron_example.svg/500px-Perceptron_example.svg.png\"/> \n",
    "\n",
    "You should **NOT** use perceptron if you need:\n",
    "- To determine difficult items and you have a few features, which helps to set a binary barrier.\n",
    "- You have lack of inputs.\n",
    "- You need to remember difficult relationships between diffirent features.\n",
    "+ see XOR problem (https://medium.com/@jayeshbahire/the-xor-problem-in-neural-networks-50006411840b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding\n",
    "Now we implement Perceptron class for any given training inputs.  \n",
    "Then we will try to determine whether perceptron is able to detect cats and dogs. Let's suppose the following inputs and a law:\n",
    "\n",
    "HAS_TAIL = 1  \n",
    "LIGHT_WEIGHT = 2  \n",
    "HAS_MUSTACHE = 3  \n",
    "HUGE = 4  \n",
    "GOOD_AT_HEARING = 5  \n",
    "SLEEP_A_LOT = 6  \n",
    "VERY_STRONG = 7  \n",
    "LITTLE_SIZE = 8  \n",
    "\n",
    "We have these animals: a cat and a dog \n",
    "Let's suppose these rules to train a perceptron:\n",
    "1. Both dogs and cats have tails\n",
    "2. Usually cats have light weight\n",
    "3. Cats are more likely have mustaches\n",
    "4. Dogs can be really huge\n",
    "5. Both dogs and cats can hear well\n",
    "6. Cats sleep a lot\n",
    "7. Usually dogs are very storng\n",
    "8. Both cats and dogs can be small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our constants\n",
    "HAS_TAIL = 0  \n",
    "LIGHT_WEIGHT = 1  \n",
    "HAS_MUSTACHE = 2  \n",
    "HUGE = 3  \n",
    "GOOD_AT_HEARING = 4  \n",
    "SLEEP_A_LOT = 5  \n",
    "VERY_STRONG = 6  \n",
    "LITTLE_SIZE = 7\n",
    "FLEXIBLE = 8\n",
    "\n",
    "# Animals\n",
    "CAT = 0\n",
    "DOG = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Seed random generator\n",
    "        np.random.seed(1)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        # Activation function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _sigmoid_derivate(self, x):\n",
    "        # Derivative functione\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, training_set, training_result, iterations=1000):\n",
    "        # Need to initilize synaptics weights\n",
    "        row, columns = training_set.shape\n",
    "\n",
    "        self.synapsis_weights = 2*np.random.random((columns, 1)) - 1\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            l1 = training_set\n",
    "            output = self.think(l1)\n",
    "            error = training_result - output\n",
    "            # [N X M] x [M x J] = [N x J]\n",
    "            adjustment = np.dot(training_set.T,error * self._sigmoid_derivate(output))\n",
    "            self.synapsis_weights += adjustment\n",
    "\n",
    "    def think(self, inputs):\n",
    "        res = self._sigmoid(np.dot(inputs, self.synapsis_weights))\n",
    "        return res\n",
    "                            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For supplied features detect what animal fits these features\n",
    "def rules(features):\n",
    "    # Firstlly we suppose all animals\n",
    "    possibile_animals = set()\n",
    "    \n",
    "    if LITTLE_SIZE in features:\n",
    "        possibile_animals.update((CAT,DOG))\n",
    "    if LIGHT_WEIGHT in features:\n",
    "        possibile_animals.update((CAT,))\n",
    "    if HAS_TAIL in features:\n",
    "        possibile_animals.update((CAT, DOG,))\n",
    "    if HAS_MUSTACHE in features:\n",
    "        possibile_animals.update((CAT,))\n",
    "    if HUGE in features:\n",
    "        possibile_animals.update((DOG),)\n",
    "    if GOOD_AT_HEARING in features:\n",
    "        possibile_animals.update((CAT, DOG),)\n",
    "    if SLEEP_A_LOT in features:\n",
    "        possibile_animals.update((CAT),)\n",
    "    if VERY_STRONG in features:\n",
    "        possibile_animals.update((DOG),)\n",
    "    if FLEXIBLE in features:\n",
    "        possibile_animals.uodate((CAT),)\n",
    "        \n",
    "    return possibile_animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training set:\n",
      "[[1. 1. 1. 0. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 1. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 1.]]\n",
      ">> Training set right output animals\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Let's put some training data\n",
    "# Each entry has 8 features - they can be any from defined in the cell above.\n",
    "#HAS_TAIL = 0  \n",
    "#LIGHT_WEIGHT = 1  \n",
    "#HAS_MUSTACHE = 2  \n",
    "#HUGE = 3  \n",
    "#GOOD_AT_HEARING = 4  \n",
    "#SLEEP_A_LOT = 5  \n",
    "#VERY_STRONG = 6  \n",
    "#LITTLE_SIZE = 7\n",
    "#FLEXIBLE = 8\n",
    "\n",
    "#Training set\n",
    "#Cat, Dog, Dog, Cat, Cat\n",
    "animals_to_train = np.zeros((5,9))\n",
    "defined_right_animals = np.array([[CAT],[DOG],[DOG],[CAT],[CAT,]])\n",
    "#Cat\n",
    "for feature in [HAS_TAIL, HAS_MUSTACHE,SLEEP_A_LOT, GOOD_AT_HEARING, LIGHT_WEIGHT, LITTLE_SIZE]:\n",
    "    animals_to_train[0][feature] = 1\n",
    "\n",
    "#Dog\n",
    "for feature in (HAS_TAIL, LIGHT_WEIGHT, GOOD_AT_HEARING):\n",
    "    animals_to_train[1][feature] = 1\n",
    "    \n",
    "#Dog#2\n",
    "for feature in (HAS_TAIL, HUGE, GOOD_AT_HEARING, VERY_STRONG):\n",
    "    animals_to_train[2][feature] = 1\n",
    "    \n",
    "#Cat#2\n",
    "for feature in (HAS_TAIL, HUGE, HAS_MUSTACHE, SLEEP_A_LOT):\n",
    "    animals_to_train[3][feature] = 1\n",
    "\n",
    "#Cat#3\n",
    "for feature in (FLEXIBLE, SLEEP_A_LOT):\n",
    "    animals_to_train[4][feature] = 1\n",
    "    \n",
    "print(\">> Training set:\")\n",
    "print(animals_to_train)\n",
    "\n",
    "print(\">> Training set right output animals\")\n",
    "print(defined_right_animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown animal features:\n",
      "Has HAS_TAIL\n",
      "Has SLEEP_A_LOT\n",
      "Has LITTLE_SIZE\n",
      "Has FLEXIBLE\n",
      "\n",
      "Our animals:\n",
      "Animal CAT 0\n",
      "Animal DOG 1\n",
      "\n",
      "Possible animals with specified features:\n",
      "{0, 1}\n",
      "\n",
      "A perceptron thinks it it:\n",
      "[[0.00204806]]\n"
     ]
    }
   ],
   "source": [
    "# Let train our network and ask her, what it thinks on random animal!\n",
    "\n",
    "neuron = Perceptron()\n",
    "# Train for 10000 iterations\n",
    "neuron.train(animals_to_train, defined_right_animals,10000)\n",
    "\n",
    "\n",
    "#HAS_TAIL = 0  \n",
    "#LIGHT_WEIGHT = 1  \n",
    "#HAS_MUSTACHE = 2  \n",
    "#HUGE = 3  \n",
    "#GOOD_AT_HEARING = 4  \n",
    "#SLEEP_A_LOT = 5  \n",
    "#VERY_STRONG = 6  \n",
    "#LITTLE_SIZE = 7 \n",
    "\n",
    "def show_features(features):\n",
    "    _features = {\n",
    "        0: 'HAS_TAIL',\n",
    "        1: 'LIGHT_WEIGHT',\n",
    "        2: 'HAS_MUSTACHE',\n",
    "        3: 'HUGE',\n",
    "        4: 'GOOD_AT_HEARING',\n",
    "        5: 'SLEEP_A_LOT',\n",
    "        6: 'VERY_STRONG',\n",
    "        7: 'LITTLE_SIZE',\n",
    "        8: \"FLEXIBLE\"\n",
    "    }\n",
    "\n",
    "    for index,foo in enumerate(features):\n",
    "        if foo:\n",
    "            print(\"Has\", _features[index])\n",
    "            \n",
    "def show_animals():\n",
    "    _animals={\n",
    "        'CAT':CAT,\n",
    "        'DOG':DOG\n",
    "    }\n",
    "    for animal in _animals:\n",
    "        print(\"Animal\",animal, _animals[animal])\n",
    "\n",
    "#possible_features = [HAS_MUSTACHE, HAS_TAIL, HUGE, VERY_STRONG, SLEEP_A_LOT, GOOD_AT_HEARING, LIGHT_WEIGHT, LITTLE_SIZE]\n",
    "possible_features = [HAS_TAIL, LITTLE_SIZE, FLEXIBLE, SLEEP_A_LOT]\n",
    "\n",
    "unknown_animal_features = np.zeros((1,9))\n",
    "for feature in possible_features:\n",
    "    unknown_animal_features[0][feature] = 1\n",
    "    \n",
    "print(\"Unknown animal features:\")\n",
    "show_features(list(unknown_animal_features[0]))\n",
    "print()\n",
    "print(\"Our animals:\")\n",
    "show_animals()\n",
    "print()\n",
    "print(\"Possible animals with specified features:\")\n",
    "print(rules(unknown_animal_features))\n",
    "print()\n",
    "print(\"A perceptron thinks it it:\")\n",
    "print(neuron.think(unknown_animal_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
